import { prisma } from "@/lib/prisma";
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";

// Access the global transcription queues (declared in websocket.ts)
// No need to re-declare, just use it
const transcriptionQueues =
  (globalThis as any).__transcriptionQueues ??
  new Map<string, { queue: any[]; processing: boolean }>();

const SUMMARIZE_PROMPT = `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó

‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠:
1. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ transcribe ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏á‡∏¥‡∏ô‡πÑ‡∏Ç‡πà" ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£", "‡∏Ñ‡∏£‡∏≤‡∏î‡πÅ‡∏™‡∏á" ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á", "‡πÄ‡∏•‡∏¥‡∏Å‡∏ï‡∏±‡πâ‡∏á" ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á")
2. ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
3. ‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏ß‡∏≤‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏°‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ ‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ

‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ:
---
**‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°**

**‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å:**
- [‡∏ß‡∏≤‡∏£‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç]

**‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:**
[‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô]

**‡∏°‡∏ï‡∏¥/‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ:**
- [‡∏°‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏ï‡∏Å‡∏•‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ]

**‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ:**
- [‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏ï‡πà‡∏≠‡πÑ‡∏õ]
---

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:`;

/**
 * Generate summary using LangChain LLM directly
 */
export async function callAgentForSummary(
  roomId: string,
  transcriptText: string,
): Promise<void> {
  try {
    console.log(
      `ü§ñ Generating summary for room ${roomId}, text length: ${transcriptText.length}`,
    );

    if (!transcriptText || transcriptText.trim().length === 0) {
      throw new Error("No transcript text to summarize");
    }

    // Initialize OpenAI Chat Model
    const model = new ChatOpenAI({
      modelName: "gpt-4o-mini", // ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ "gpt-4" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
      temperature: 0.3, // ‡∏ï‡πà‡∏≥‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
      openAIApiKey: process.env.OPENAI_API_KEY,
    });

    console.log(`üìù Calling LLM to fix typos and summarize...`);

    // Call LLM with system and user messages
    const messages = [
      new SystemMessage(SUMMARIZE_PROMPT),
      new HumanMessage(transcriptText),
    ];

    const response = await model.invoke(messages);
    const summaryText = response.content as string;

    console.log(
      `‚úÖ Summary generated for room ${roomId}, length: ${summaryText.length}`,
    );

    // Update room with final summary
    await prisma.room.update({
      where: { id: roomId },
      data: {
        finalSummary: summaryText,
        status: "ENDED",
        endedAt: new Date(),
      },
    });

    console.log(`‚úÖ Room ${roomId} updated with summary`);
  } catch (error) {
    console.error(`‚ùå Failed to generate summary for room ${roomId}:`, error);

    // Update room with error status
    await prisma.room.update({
      where: { id: roomId },
      data: {
        finalSummary: `‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ\n\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: ${error instanceof Error ? error.message : "Unknown error"}\n\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö:\n${transcriptText}`,
        status: "ENDED",
        endedAt: new Date(),
      },
    });

    throw error;
    throw error;
  }
}

/**
 * Wait for all transcription queues to finish for a specific room
 */
export async function waitForTranscriptionComplete(
  roomId: string,
): Promise<string> {
  return new Promise((resolve) => {
    const maxWaitTime = 30000; // 30 seconds max wait
    const checkInterval = 500; // Check every 500ms
    let waitTime = 0;
    let allTranscribedText = "";

    const checkComplete = async () => {
      const roomQueue = transcriptionQueues.get(roomId);

      if (
        !roomQueue ||
        (roomQueue.queue.length === 0 && !roomQueue.processing)
      ) {
        // Queue is empty and not processing, collect all transcribed text
        try {
          const transcriptChunks = await prisma.transcriptChunk.findMany({
            where: { roomId },
            orderBy: { createdAt: "asc" },
          });

          allTranscribedText = transcriptChunks
            .map((chunk) => chunk.content)
            .join(" ");
          console.log(
            `‚úÖ All transcription complete for room ${roomId}, total text length: ${allTranscribedText.length}`,
          );
          resolve(allTranscribedText);
          return;
        } catch (error) {
          console.error("Error collecting transcribed text:", error);
          resolve("");
          return;
        }
      }

      waitTime += checkInterval;
      if (waitTime >= maxWaitTime) {
        console.log(
          `‚è∞ Timeout waiting for transcription to complete for room ${roomId}`,
        );
        // Still try to collect whatever text we have
        try {
          const transcriptChunks = await prisma.transcriptChunk.findMany({
            where: { roomId },
            orderBy: { createdAt: "asc" },
          });

          allTranscribedText = transcriptChunks
            .map((chunk) => chunk.content)
            .join(" ");
          resolve(allTranscribedText);
        } catch (error) {
          resolve("");
        }
        return;
      }

      setTimeout(checkComplete, checkInterval);
    };

    checkComplete();
  });
}
